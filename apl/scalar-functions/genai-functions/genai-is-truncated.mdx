---
title: 'genai_is_truncated'
description: 'This page explains how to use the genai_is_truncated function in APL.'
---

The `genai_is_truncated` function checks whether an AI model response was truncated due to reaching token limits or other constraints. It analyzes the finish reason returned by the API to determine if the response was cut short.

You can use this function to identify incomplete responses, monitor quality issues, detect token limit problems, or track when conversations need continuation.

## For users of other query languages

If you come from other query languages, this section explains how to adjust your existing queries to achieve the same results in APL.

<AccordionGroup>
<Accordion title="Splunk SPL users">

In Splunk SPL, you would check the finish_reason field manually.

<CodeGroup>
```sql Splunk example
| eval is_truncated=if(finish_reason="length", "true", "false")
```

```kusto APL equivalent
['ai-logs']
| extend is_truncated = genai_is_truncated(messages, finish_reason)
```
</CodeGroup>

</Accordion>
<Accordion title="ANSI SQL users">

In ANSI SQL, you would check the finish_reason field value.

<CodeGroup>
```sql SQL example
SELECT 
  conversation_id,
  CASE WHEN finish_reason = 'length' THEN true ELSE false END as is_truncated
FROM ai_logs
```

```kusto APL equivalent
['ai-logs']
| extend is_truncated = genai_is_truncated(messages, finish_reason)
```
</CodeGroup>

</Accordion>
</AccordionGroup>

## Usage

### Syntax

```kusto
genai_is_truncated(messages, finish_reason)
```

### Parameters

- **messages** (dynamic, required): An array of message objects from a GenAI conversation. Each message typically contains `role` and `content` fields.
- **finish_reason** (string, required): The finish reason returned by the AI API (such as 'stop', 'length', 'content_filter', 'tool_calls').

### Returns

Returns a boolean value: `true` if the response was truncated (typically when finish_reason is 'length'), `false` otherwise.

## Use case examples

<Tabs>
<Tab title="Log analysis">

Monitor the rate of truncated responses to understand if token limits are causing quality issues.

**Query**

```kusto
['sample-http-logs']
| where uri contains '/api/chat'
| extend finish = tostring(todynamic(response_body)['choices'][0]['finish_reason'])
| extend is_truncated = genai_is_truncated(todynamic(response_body)['messages'], finish)
| summarize 
    truncated_count = countif(is_truncated),
    total_count = count(),
    truncation_rate = round(100.0 * countif(is_truncated) / count(), 2)
by bin(_time, 1h)
```

[Run in Playground](https://play.axiom.co/axiom-play-qf1k/query?initForm=%7B%22apl%22%3A%22%5B'sample-http-logs'%5D%20%7C%20where%20uri%20contains%20'%2Fapi%2Fchat'%20%7C%20extend%20finish%20%3D%20tostring(todynamic(response_body)%5B'choices'%5D%5B0%5D%5B'finish_reason'%5D)%20%7C%20extend%20is_truncated%20%3D%20genai_is_truncated(todynamic(response_body)%5B'messages'%5D%2C%20finish)%20%7C%20summarize%20truncated_count%20%3D%20countif(is_truncated)%2C%20total_count%20%3D%20count()%2C%20truncation_rate%20%3D%20round(100.0%20*%20countif(is_truncated)%20%2F%20count()%2C%202)%20by%20bin(_time%2C%201h)%22%7D)

**Output**

| _time | truncated_count | total_count | truncation_rate |
|-------|-----------------|-------------|-----------------|
| 2024-01-15T10:00:00Z | 45 | 1450 | 3.10 |
| 2024-01-15T11:00:00Z | 52 | 1523 | 3.41 |

This query tracks the rate of truncated responses over time, helping you identify when token limits are causing problems.

</Tab>
<Tab title="OpenTelemetry traces">

Identify which services experience the most truncation issues to optimize token usage.

**Query**

```kusto
['otel-demo-traces']
| where ['service.name'] == 'frontend' and kind == 'server'
| extend finish_reason = tostring(attributes['ai.finish_reason'])
| extend truncated = genai_is_truncated(todynamic(attributes['ai.messages']), finish_reason)
| where truncated == true
| summarize truncation_count = count() by ['service.name'], operation = name
```

[Run in Playground](https://play.axiom.co/axiom-play-qf1k/query?initForm=%7B%22apl%22%3A%22%5B'otel-demo-traces'%5D%20%7C%20where%20%5B'service.name'%5D%20%3D%3D%20'frontend'%20and%20kind%20%3D%3D%20'server'%20%7C%20extend%20finish_reason%20%3D%20tostring(attributes%5B'ai.finish_reason'%5D)%20%7C%20extend%20truncated%20%3D%20genai_is_truncated(todynamic(attributes%5B'ai.messages'%5D)%2C%20finish_reason)%20%7C%20where%20truncated%20%3D%3D%20true%20%7C%20summarize%20truncation_count%20%3D%20count()%20by%20%5B'service.name'%5D%2C%20operation%20%3D%20name%22%7D)

**Output**

| service.name | operation | truncation_count |
|--------------|-----------|------------------|
| frontend | chat_completion | 45 |
| frontend | document_summary | 23 |

This query identifies which operations have the most truncation issues, helping you prioritize optimization efforts.

</Tab>
<Tab title="Security logs">

Monitor for patterns of truncated responses that might indicate attempts to extract large amounts of data.

**Query**

```kusto
['sample-http-logs']
| where uri contains '/api/ai'
| extend finish = tostring(todynamic(response_body)['choices'][0]['finish_reason'])
| extend truncated = genai_is_truncated(todynamic(response_body)['messages'], finish)
| where truncated == true
| summarize truncation_count = count() by id, ['geo.country']
| where truncation_count > 10
| order by truncation_count desc
```

[Run in Playground](https://play.axiom.co/axiom-play-qf1k/query?initForm=%7B%22apl%22%3A%22%5B'sample-http-logs'%5D%20%7C%20where%20uri%20contains%20'%2Fapi%2Fai'%20%7C%20extend%20finish%20%3D%20tostring(todynamic(response_body)%5B'choices'%5D%5B0%5D%5B'finish_reason'%5D)%20%7C%20extend%20truncated%20%3D%20genai_is_truncated(todynamic(response_body)%5B'messages'%5D%2C%20finish)%20%7C%20where%20truncated%20%3D%3D%20true%20%7C%20summarize%20truncation_count%20%3D%20count()%20by%20id%2C%20%5B'geo.country'%5D%20%7C%20where%20truncation_count%20%3E%2010%20%7C%20order%20by%20truncation_count%20desc%22%7D)

**Output**

| id | geo.country | truncation_count |
|----|--------------|------------------|
| user_789 | US | 34 |
| user_234 | CN | 18 |

This query identifies users with frequent truncated responses, which might indicate data extraction attempts or other suspicious behavior.

</Tab>
</Tabs>

## List of related functions

- [genai_estimate_tokens](/apl/scalar-functions/genai-functions/genai-estimate-tokens): Estimates token count. Use this to predict if responses might be truncated before making API calls.
- [genai_conversation_turns](/apl/scalar-functions/genai-functions/genai-conversation-turns): Counts conversation turns. Analyze this alongside truncation to understand context length issues.
- [genai_extract_assistant_response](/apl/scalar-functions/genai-functions/genai-extract-assistant-response): Extracts assistant responses. Use this to examine truncated responses.
- [strlen](/apl/scalar-functions/string-functions#strlen): Returns string length. Use this to analyze the length of truncated responses.

