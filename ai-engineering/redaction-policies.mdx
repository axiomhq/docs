---
title: "Redaction policies"
description: "This page explains how to use redaction policies in the Axiom AI SDK to control what data is captured in AI spans"
---

Axiom AI SDK provides flexible redaction policies to control what data is captured in OpenTelemetry spans. This allows you to balance observability needs with privacy and compliance requirements.

### Policy options

Redaction policies control two key aspects of data capture:

- `captureMessageContent` defines whether to include full prompt and response text in spans.
- `mirrorToolPayloadOnToolSpan` defines whether to duplicate tool arguments and results on tool spans for easier querying

<ParamField path="captureMessageContent" type="'full' | 'off'" default="'full'">
Controls whether prompt and response text is included in chat spans.

- `'full'`: Include complete message content
- `'off'`: Exclude all message content
</ParamField>

<ParamField path="mirrorToolPayloadOnToolSpan" type="boolean" default="true">
Controls whether tool arguments and results are duplicated on tool spans.

- `true`: Mirror tool data for easier querying
- `false`: Only capture tool metadata (name, description)
</ParamField>

## Configuration methods

You can configure different policies globally or per-operation.

Redaction policies are resolved in the following order (highest to lowest precedence):

1. **Per-operation policy** (via `withSpan` options)
2. **Global policy** (via `initAxiomAI`)
3. **Default policy** (`RedactionPolicy.AxiomDefault`)

<Steps>
<Step title="Check per-operation policy">
If a `redactionPolicy` is provided to `withSpan`, it takes highest precedence.
</Step>

<Step title="Fall back to global policy">
If no per-operation policy exists, use the policy from `initAxiomAI`.
</Step>

<Step title="Use default policy">
If no policies are configured, default to `RedactionPolicy.AxiomDefault`.
</Step>
</Steps>

## Built-in redaction policies

### Axiom default policy

By default, Axiom AI SDK captures all data for maximum observability.

To capture all data for comprehensive observability and debugging, use the following policy:

```ts
RedactionPolicy.AxiomDefault = {
  captureMessageContent: 'full',
  mirrorToolPayloadOnToolSpan: true
}
```

**What gets captured:**
- Full prompt text and AI responses in chat spans
- Complete tool arguments and return values on tool spans
- All standard OpenTelemetry attributes (model name, token usage, etc.)

**Use when:**
- You need full visibility into AI interactions
- Data privacy is not a concern
- Debugging complex AI workflows

### OpenTelemetry default policy

Follows OpenTelemetry semantic conventions by excluding sensitive content.

```typescript
RedactionPolicy.OpenTelemetryDefault = {
  captureMessageContent: 'off',
  mirrorToolPayloadOnToolSpan: false
}
```

**What gets captured:**
- Model metadata (name, provider, version)
- Token usage and performance metrics
- Error information and status codes

**What gets excluded:**
- Prompt text and AI responses
- Tool arguments and return values

**Use when:**
- Handling sensitive or personal data
- Compliance requirements restrict data capture
- You only need performance and error metrics

## Configuration Methods

### Global Configuration

Set a default redaction policy for your entire application using `initAxiomAI`:

<CodeGroup>
```typescript Full Data Capture
import { initAxiomAI, RedactionPolicy } from '@axiomhq/axiom-ai';
import { trace } from '@opentelemetry/api';

initAxiomAI({
  tracer: trace.getTracer('my-app'),
  redactionPolicy: RedactionPolicy.AxiomDefault
});
```

```typescript Privacy-First
import { initAxiomAI, RedactionPolicy } from '@axiomhq/axiom-ai';
import { trace } from '@opentelemetry/api';

initAxiomAI({
  tracer: trace.getTracer('my-app'),
  redactionPolicy: RedactionPolicy.OpenTelemetryDefault
});
```
</CodeGroup>

### Per-operation override

Override the global policy for specific operations using `withSpan`:

```typescript
import { withSpan, RedactionPolicy } from '@axiomhq/axiom-ai';
import { generateText } from 'ai';

// Global policy is AxiomDefault, but this operation uses privacy-first
const result = await withSpan(
  { capability: 'customer_support', step: 'handle_sensitive_query' },
  async (span) => {
    span.setAttribute('user.id', userId);
    return generateText({
      model: wrappedModel,
      prompt: 'Process this sensitive customer data...'
    });
  },
  { redactionPolicy: RedactionPolicy.OpenTelemetryDefault }
);
```

<Tip>
Per-operation policies take precedence over global policies, allowing you to handle sensitive operations differently while maintaining full observability elsewhere.
</Tip>

## Custom redaction policies

Create custom policies by defining an `AxiomAIRedactionPolicy` object:

```typescript
import type { AxiomAIRedactionPolicy } from '@axiomhq/axiom-ai';

// Custom policy: capture messages but not tool payloads
const customPolicy: AxiomAIRedactionPolicy = {
  captureMessageContent: 'full',
  mirrorToolPayloadOnToolSpan: false
};

initAxiomAI({
  tracer: trace.getTracer('my-app'),
  redactionPolicy: customPolicy
});
```

## Implementation examples

### Multi-tenant application

Different redaction policies for different customer tiers:

```typescript
async function handleUserRequest(userId: string, prompt: string) {
  const user = await getUser(userId);
  
  // Enterprise customers get full observability
  // Free tier users get privacy-first approach
  const policy = user.tier === 'enterprise' 
    ? RedactionPolicy.AxiomDefault 
    : RedactionPolicy.OpenTelemetryDefault;

  return withSpan(
    { capability: 'chat', step: 'generate_response' },
    async (span) => {
      span.setAttribute('user.tier', user.tier);
      return generateText({ model: wrappedModel, prompt });
    },
    { redactionPolicy: policy }
  );
}
```

### Compliance-aware tool usage

Capture AI interactions but redact sensitive tool operations:

```typescript
// Global policy captures AI conversations
initAxiomAI({
  tracer: trace.getTracer('compliance-app'),
  redactionPolicy: RedactionPolicy.AxiomDefault
});

// But sensitive operations use privacy-first approach
async function processPayment(paymentData: PaymentInfo) {
  return withSpan(
    { capability: 'payment', step: 'process_transaction' },
    async (span) => {
      span.setAttribute('payment.method', paymentData.method);
      // Tool arguments/results won't be captured due to redaction policy
      return paymentTool.execute(paymentData);
    },
    { redactionPolicy: RedactionPolicy.OpenTelemetryDefault }
  );
}
```

### Development vs production

Use different policies based on environment:

```typescript
const redactionPolicy = process.env.NODE_ENV === 'development'
  ? RedactionPolicy.AxiomDefault  // Full data in dev
  : RedactionPolicy.OpenTelemetryDefault;  // Privacy-first in prod

initAxiomAI({
  tracer: trace.getTracer('my-app'),
  redactionPolicy
});
```

## What gets captured

### With AxiomDefault policy

<Tabs>
<Tab title="Chat Spans">
```json
{
  "gen_ai.operation.name": "chat",
  "gen_ai.request.model": "gpt-4o-mini",
  "gen_ai.input.messages": "[{\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":\"Hello, how are you?\"}]}]",
  "gen_ai.output.messages": "[{\"role\":\"assistant\",\"content\":\"I'm doing well, thank you for asking!\"}]",
  "gen_ai.usage.input_tokens": 12,
  "gen_ai.usage.output_tokens": 15,
  "gen_ai.usage.total_tokens": 27
}
```
</Tab>

<Tab title="Tool Spans">
```json
{
  "gen_ai.tool.name": "weather_lookup",
  "gen_ai.tool.description": "Get current weather for a location",
  "gen_ai.tool.arguments": "{\"location\":\"San Francisco\",\"units\":\"celsius\"}",
  "gen_ai.tool.message": "{\"temperature\":18,\"condition\":\"partly cloudy\"}"
}
```
</Tab>
</Tabs>

### With OpenTelemetryDefault policy

<Tabs>
<Tab title="Chat Spans">
```json
{
  "gen_ai.operation.name": "chat",
  "gen_ai.request.model": "gpt-4o-mini",
  "gen_ai.usage.input_tokens": 12,
  "gen_ai.usage.output_tokens": 15,
  "gen_ai.usage.total_tokens": 27
}
```

<Note>
Message content (`gen_ai.input.messages` and `gen_ai.output.messages`) is excluded for privacy.
</Note>
</Tab>

<Tab title="Tool Spans">
```json
{
  "gen_ai.tool.name": "weather_lookup",
  "gen_ai.tool.description": "Get current weather for a location"
}
```

<Note>
Tool arguments and results (`gen_ai.tool.arguments` and `gen_ai.tool.message`) are excluded for privacy.
</Note>
</Tab>
</Tabs>

## Best practices

### Start privacy-first

<Tip>
Begin with `RedactionPolicy.OpenTelemetryDefault` and selectively enable full capture only where needed. This approach minimizes privacy risks while maintaining essential observability.
</Tip>

### Document your policies

Clearly document which redaction policies are used in different parts of your application:

```typescript
// Document policy decisions with comments
const REDACTION_POLICIES = {
  // Full observability for internal tools
  INTERNAL_TOOLS: RedactionPolicy.AxiomDefault,
  
  // Privacy-first for customer data
  CUSTOMER_FACING: RedactionPolicy.OpenTelemetryDefault,
  
  // Custom policy for analytics
  ANALYTICS: {
    captureMessageContent: 'full',
    mirrorToolPayloadOnToolSpan: false
  }
} as const;
```

### Test your policies

Verify that your redaction policies work as expected:

```typescript
// Test that sensitive data is properly redacted
it('should redact customer data in production spans', async () => {
  const spans = await captureSpans(() => 
    processCustomerQuery('sensitive customer data')
  );
  
  const chatSpan = spans.find(s => s.name === 'chat gpt-4o-mini');
  expect(chatSpan.attributes['gen_ai.input.messages']).toBeUndefined();
  expect(chatSpan.attributes['gen_ai.output.messages']).toBeUndefined();
});
```

### Monitor policy effectiveness

Use Axiom queries to verify your redaction policies are working correctly:

```apl
['your-dataset']
| where ['gen_ai.operation.name'] == "chat"
| extend has_input_messages = isnotnull(['gen_ai.input.messages'])
| extend has_output_messages = isnotnull(['gen_ai.output.messages'])
| summarize 
    total_spans = count(),
    spans_with_content = countif(has_input_messages or has_output_messages)
| extend redaction_rate = (total_spans - spans_with_content) * 100.0 / total_spans
```

## Troubleshooting

### Policy not applied

If your redaction policy isn't working:

<AccordionGroup>
<Accordion title="Check initialization order">
Ensure `initAxiomAI` is called before any AI operations:

```typescript
// ❌ Wrong: AI operation before initialization
const result = await generateText({ model, prompt });
initAxiomAI({ tracer, redactionPolicy });

// ✅ Correct: Initialize first
initAxiomAI({ tracer, redactionPolicy });
const result = await generateText({ model, prompt });
```
</Accordion>

<Accordion title="Verify policy precedence">
Remember that per-operation policies override global policies:

```typescript
// Global policy is OpenTelemetryDefault
initAxiomAI({ 
  tracer, 
  redactionPolicy: RedactionPolicy.OpenTelemetryDefault 
});

// This operation will still capture full data due to override
await withSpan(
  { capability: 'test', step: 'test' },
  async () => generateText({ model, prompt }),
  { redactionPolicy: RedactionPolicy.AxiomDefault } // Override wins
);
```
</Accordion>

<Accordion title="Check span attributes">
Use Axiom's live tail or query interface to verify which attributes are present:

```apl
['your-dataset']
| where ['gen_ai.operation.name'] == "chat"
| project 
    timestamp,
    ['gen_ai.request.model'],
    has_input = isnotnull(['gen_ai.input.messages']),
    has_output = isnotnull(['gen_ai.output.messages'])
| take 10
```
</Accordion>
</AccordionGroup>

### Performance considerations

<Warning>
Capturing full message content increases span size and storage costs. Monitor your data volume and adjust policies accordingly.
</Warning>

Use Axiom to monitor span sizes:

```apl
['your-dataset']
| where ['gen_ai.operation.name'] == "chat"
| extend message_size = strlen(tostring(['gen_ai.input.messages'])) + strlen(tostring(['gen_ai.output.messages']))
| summarize 
    avg_size = avg(message_size),
    max_size = max(message_size),
    total_volume = sum(message_size)
by bin(timestamp, 1h)
```

## Related documentation

<CardGroup cols={2}>
<Card title="AI SDK Instrumentation" icon="chart-line" href="/ai-engineering/observe/axiom-ai-sdk-instrumentation">
Learn how to instrument your AI applications with the Axiom AI SDK
</Card>

<Card title="OpenTelemetry Attributes" icon="tags" href="/ai-engineering/observe/gen-ai-attributes">
Understand the OpenTelemetry attributes captured by the AI SDK
</Card>
</CardGroup>
