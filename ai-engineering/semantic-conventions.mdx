---
title: "Semantic Conventions"
keywords: ["ai engineering", "opentelemetry", "semantic conventions", "telemetry", "traces", "spans"]
---

import { Badge } from "/snippets/badge.jsx"

Axiom supports two approaches for sending generative AI telemetry:

<CardGroup cols={2}>
  <Card title="Axiom AI SDK" icon="bolt" href="/ai-engineering/quickstart#installation">
    **Fastest setup** - Use our wrapper around the Vercel AI SDK for automatic instrumentation with minimal code changes. See the [Quickstart](/ai-engineering/quickstart) guide.
  </Card>
  <Card title="Custom OpenTelemetry" icon="code" href="#required-attributes">
    **Full control** - Send traces manually using any OpenTelemetry-compatible instrumentation that follows our semantic conventions (this page).
  </Card>
</CardGroup>

If you use the Axiom AI SDK, it automatically captures and sends traces with the correct semantic conventions, so you can skip the rest of this page.

If you prefer to use your own tooling instead of the Axiom AI SDK, you can send OpenTelemetry traces directly to Axiom following our semantic conventions. This approach gives you full control over your instrumentation while ensuring compatibility with Axiom's AI Engineering features.

If you are setting up OpenTelemetry for the first time, see [Send OpenTelemetry data to Axiom](/send-data/opentelemetry#send-opentelemetry-data-to-axiom) for examples in multiple languages.

<Note>
Axiom's conventions for AI spans are based on version 1.37 of the [OpenTelemetry Semantic conventions for generative client AI spans](https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-spans/).

Axiom requires two additional attributes: `gen_ai.capability.name` and `gen_ai.step.name`. More on these below.
</Note>

## Required attributes

To ensure your spans are properly recognized by Axiom's AI Engineering features, the following attributes are required.

### `gen_ai.operation.name`

AI Spans are identified by the `gen_ai.operation.name` attribute. This is a required attribute in the [OpenTelemetry specification](https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-spans/).

Axiom currently provides custom UI for the following operations:

- `chat` - Chat completion
- `execute_tool` - Tool execution

Other possible values include:

- `generate_content` - Multimodal content generation
- `embeddings` - Vector embeddings
- `create_agent` - Creating AI agents
- `invoke_agent` - Invoking existing agents  
- `text_completion` - Text completion (legacy, has been deprecated by OpenAI and many other providers)

For more information, see [Gen AI Attributes](https://opentelemetry.io/docs/specs/semconv/registry/attributes/gen-ai/#gen-ai-operation-name).

### `gen_ai.capability.name` and `gen_ai.step.name`

The purpose of these attributes is to provide context for AI operations and allow you to break your operations down by feature and step, especially when querying.

[Capability](/ai-engineering/concepts#capability) can be thought of as a feature or function of the AI system, while `step` refers to a specific stage in the operation. In general, each LLM call will be one step. A capability may contain multiple steps.

### `axiom.gen_ai` attributes

These attributes currently have no TKTK

- `axiom.gen_ai.schema_url` - The schema URL for the Axiom AI conventions. Currently: `https://axiom.co/ai/schemas/0.0.2`
- `axiom.gen_ai.sdk.name` - The name of the SDK (e.g., `my-ai-instrumentation-sdk`)
- `axiom.gen_ai.sdk.version` - The version of the SDK (e.g., `1.2.3`)

### Span naming

Span names should follow the the OpenTelemetry conventions:

- `generate_text {gen_ai.request.model}`
- `execute_tool {gen_ai.tool.name}`
- `embeddings {gen_ai.request.model}`
- `generate_content {gen_ai.request.model}`
- `create_agent {gen_ai.agent.name}`
- `invoke_agent {gen_ai.agent.name}`

### Core attributes

Beyond `gen_ai.operation.name`, these attributes enable Axiom's AI features:

| Attribute | Type | Required | Description |
| --------- | ---- | -------- | ----------- |
| `gen_ai.provider.name` | string | Required | Provider (openai, anthropic, aws.bedrock, etc.) |
| `gen_ai.request.model` | string | When available | Model requested (gpt-4, claude-3, etc.) |
| `gen_ai.response.model` | string | When available | Model that fulfilled the request |
| `gen_ai.input.messages` | Messages[] | Recommended | Input conversation history (see Messages below) |
| `gen_ai.output.messages` | Messages[] | Recommended | Model response messages (see Messages below) |
| `gen_ai.usage.input_tokens` | integer | Recommended | Input token count |
| `gen_ai.usage.output_tokens` | integer | Recommended | Output token count |
| `gen_ai.request.choice_count` | integer | When !=1 | Number of completion choices requested |
| `gen_ai.response.id` | string | Recommended | Unique response identifier |
| `gen_ai.response.finish_reasons` | string[] | Recommended | Why generation stopped |
| `server.address` | string | Recommended | AI service hostname |
| `server.port` | integer | When applicable | AI service port |

### Agent-specific attributes

For agent operations (`create_agent`, `invoke_agent`), include these additional attributes:

| Attribute | Type | Required | Description |
| --------- | ---- | -------- | ----------- |
| `gen_ai.agent.id` | string | When available | Unique agent identifier |
| `gen_ai.agent.name` | string | When available | Human-readable agent name |
| `gen_ai.agent.description` | string | When available | Agent description/purpose |
| `gen_ai.conversation.id` | string | When available | Conversation/session identifier |
| `gen_ai.system_instructions` | any | Optional | System prompt for the agent |

### Tool execution attributes  

For tool operations (`execute_tool`), include these additional attributes:

| Attribute | Type | Required | Description |
| --------- | ---- | -------- | ----------- |
| `gen_ai.tool.name` | string | Required | Name of the executed tool |
| `gen_ai.tool.call.id` | string | When available | Tool call identifier |
| `gen_ai.tool.type` | string | When available | Tool type (function, extension, datastore) |
| `gen_ai.tool.description` | string | When available | Tool description |
| `gen_ai.tool.arguments` | string | When available | Tool arguments |
| `gen_ai.tool.message` | string | When available | Tool message |

For more information, see [Gen AI Attributes](https://opentelemetry.io/docs/specs/semconv/registry/attributes/gen-ai/#genai-attributes).

### Messages

Messages support four different roles, each with specific content formats:

Messages follow OpenTelemetry's structured format:

**System messages**
```json
{
  "role": "system",
  "parts": [
    {"type": "text", "content": "You are a helpful assistant"}
  ]
}
```

**User messages**
```json
{
  "role": "user",
  "parts": [
    {"type": "text", "content": "Weather in Paris?"}
  ]
}
```

**Assistant messages**
```json
{
  "role": "assistant", 
  "parts": [
    {"type": "text", "content": "Hi there!"},
    {"type": "tool_call", "id": "call_123", "name": "get_weather", "arguments": {"location": "Paris"}}
  ],
  "finish_reason": "stop"
}
```

**Tool messages**
```json
{
  "role": "tool",
  "parts": [
    {"type": "tool_call_response", "id": "call_123", "response": "rainy, 57Â°F"}
  ]
}
```

**Content part types:**
- `text` - Text content with `content` field
- `tool_call` - Tool invocation with `id`, `name`, `arguments`
- `tool_call_response` - Tool result with `id`, `response`

See more information in [Recording content on attributes](https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-spans/#recording-content-on-attributes), as well as the JSON schema for [inputs](https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-input-messages.json) and [outputs](https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-output-messages.json).

## Example trace structure

### Chat completion

Here is an example of a properly structured chat completion trace:

<CodeGroup>

```typescript TypeScript
import { trace, SpanKind } from '@opentelemetry/api';

const tracer = trace.getTracer('my-ai-app');

// Create a span for the AI operation
const span = tracer.startSpan('chat gpt-4', {
  kind: SpanKind.CLIENT
});

// (Your AI operation logic here...)

span.setAttributes({
  // Set operation name
  'gen_ai.operation.name': 'chat',
  // set capability and step
  'gen_ai.capability.name': 'customer_support',
  'gen_ai.step.name': 'respond_to_greeting',
  // set other attributes
  'gen_ai.provider.name': 'openai',
  'gen_ai.request.model': 'gpt-4',
  'gen_ai.response.model': 'gpt-4',
  'gen_ai.usage.input_tokens': 150,
  'gen_ai.usage.output_tokens': 75,
  'gen_ai.input.messages': JSON.stringify([
    { role: 'user', parts: [{ type: 'text', content: 'Hello, how are you?' }] }
  ]),
  'gen_ai.output.messages': JSON.stringify([
    { role: 'assistant', parts: [{ type: 'text', content: 'I\'m doing well, thank you!' }], finish_reason: 'stop' }
  ])
});

span.end();
```

```python Python
from opentelemetry import trace
from opentelemetry.trace import SpanKind
import json

tracer = trace.get_tracer("my-ai-app")

# Create a span for the AI operation
with tracer.start_as_current_span("chat gpt-4", kind=SpanKind.CLIENT) as span:
    # (Your AI operation logic here...)

    span.set_attributes({
        # Set operation name
        "gen_ai.operation.name": "chat",
        # Set capability and step
        "gen_ai.capability.name": "customer_support",
        "gen_ai.step.name": "respond_to_greeting",
        # Set other attributes
        "gen_ai.provider.name": "openai",
        "gen_ai.request.model": "gpt-4",
        "gen_ai.response.model": "gpt-4",
        "gen_ai.usage.input_tokens": 150,
        "gen_ai.usage.output_tokens": 75,
        "gen_ai.input.messages": json.dumps([
            {"role": "user", "parts": [{"type": "text", "content": "Hello, how are you?"}]}
        ]),
        "gen_ai.output.messages": json.dumps([
            {"role": "assistant", "parts": [{"type": "text", "content": "I'm doing well, thank you!"}], "finish_reason": "stop"}
        ])
    })
    
```

</CodeGroup>

### Tool execution

Here is an example of a tool execution within an agent:

<CodeGroup>

```typescript Node.js
import { trace, SpanKind } from '@opentelemetry/api';

const tracer = trace.getTracer('my-agent-app');

// Create a span for tool execution
const span = tracer.startSpan('execute_tool get_weather', {
  kind: SpanKind.CLIENT
});

// (Your tool call logic here...)

// Set tool-specific attributes
span.setAttributes({
  // Set operation name
  'gen_ai.operation.name': 'execute_tool',
  // Set capability and step
  'gen_ai.capability.name': 'weather_assistance',
  'gen_ai.step.name': 'fetch_current_weather',
  // Set other attributes
  'gen_ai.tool.name': 'get_weather',
  'gen_ai.tool.type': 'function',
  'gen_ai.tool.call.id': 'call_abc123',
  'gen_ai.tool.arguments': JSON.stringify({ location: 'New York', units: 'celsius' }),
  'gen_ai.tool.message': JSON.stringify({ temperature: 22, condition: 'sunny', humidity: 65 }),
});

span.end();
```

```python Python
from opentelemetry import trace
from opentelemetry.trace import SpanKind
import json

tracer = trace.get_tracer("my-agent-app")

# Create a span for tool execution  
with tracer.start_as_current_span("execute_tool get_weather", kind=SpanKind.CLIENT) as span:
    span.set_attributes({
        # Set operation name
        "gen_ai.operation.name": "execute_tool",
        # Set capability and step
        "gen_ai.step.name": "fetch_current_weather",
        "gen_ai.capability.name": "weather_assistance",
        # Set other attributes
        "gen_ai.tool.name": "get_weather",
        "gen_ai.tool.type": "function",
        "gen_ai.tool.call.id": "call_abc123",
        "gen_ai.tool.arguments": json.dumps({"location": "New York", "units": "celsius"}),
        "gen_ai.tool.message": json.dumps({"temperature": 22, "condition": "sunny", "humidity": 65}),
    })
```

</CodeGroup>

## What's next?

Once you're sending traces with the proper semantic conventions:

- Explore the [Rudder workflow](/ai-engineering/create) to learn about systematic AI development
- View your traces in Axiom's Console using the AI Trace Waterfall visualization
- Set up monitors and alerts based on your AI telemetry data

<Info>
Need help implementing these conventions? Check out the [Quickstart](/ai-engineering/quickstart) guide for a faster setup using Axiom's AI SDK, or reach out to [support](https://axiom.co/support) for assistance with custom implementations.
</Info>
