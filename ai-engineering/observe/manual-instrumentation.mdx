---
title: "Manual Instrumentation"
keywords: ["ai engineering", "opentelemetry", "semantic conventions", "telemetry", "traces", "spans"]
---

Axiom supports two approaches for sending generative AI telemetry:

<CardGroup cols={2}>
  <Card title="Axiom AI SDK" icon="bolt" href="/ai-engineering/observe/typescript-sdk">
    **TypeScript** - Use with the Vercel AI SDK for automatic instrumentation with minimal code changes.
  </Card>
  <Card title="Custom OpenTelemetry" icon="code" href="#required-attributes">
    **Language-agnostic OpenTelemetry** - Send traces using your own tooling following our semantic conventions. Works with any language or SDK. (this page).
  </Card>
</CardGroup>

If you use the Axiom AI SDK, it automatically captures and sends traces with the correct semantic conventions, so you can skip the rest of this page and use the [TypeScript SDK](/ai-engineering/observe/typescript-sdk) guide instead.

If you prefer to use your own tooling instead of the Axiom AI SDK, you can send OpenTelemetry traces directly to Axiom following our semantic conventions. This approach gives you full control over your instrumentation while ensuring compatibility with Axiom's AI Engineering features.

<Info>
Both SDK and custom OpenTelemetry approaches emit identical `gen_ai.*` attributes, so all the telemetry analysis features work the same way.
</Info>

If you are setting up OpenTelemetry for the first time, see [Send OpenTelemetry data to Axiom](/send-data/opentelemetry#send-opentelemetry-data-to-axiom) for examples in multiple languages.

<Note>
Axiom's conventions for AI spans are based on version 1.37 of the [OpenTelemetry Semantic conventions for generative client AI spans](https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-spans/).

Axiom requires two additional attributes: `gen_ai.capability.name` and `gen_ai.step.name`.
</Note>

## Required attributes

To ensure your spans are properly recognized by Axiom's AI Engineering features, the following attributes are required.

### `gen_ai.operation.name`

AI Spans are identified by the `gen_ai.operation.name` attribute. This is a required attribute in the [OpenTelemetry specification](https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-spans/).

Axiom currently provides custom UI for the following operations:

- `chat` - Chat completion
- `execute_tool` - Tool execution

Other possible values include:

- `generate_content` - Multimodal content generation
- `embeddings` - Vector embeddings
- `create_agent` - Creating AI agents
- `invoke_agent` - Invoking existing agents  
- `text_completion` - Text completion (legacy, has been deprecated by OpenAI and many other providers)

For more information, see [Gen AI Attributes](https://opentelemetry.io/docs/specs/semconv/registry/attributes/gen-ai/#gen-ai-operation-name).

### `gen_ai.capability.name` and `gen_ai.step.name`

The purpose of these attributes is to provide context for AI operations and allow you to break your operations down by feature and step, especially when querying.

A [capability](/ai-engineering/concepts#capability) can be thought of as a feature or function of the AI system, while a step refers to a specific stage in the operation. In general, each LLM call will be one step. A capability may contain multiple steps.

## `axiom.gen_ai` attributes

- `axiom.gen_ai.schema_url` - The schema URL for the Axiom AI conventions. Currently: `https://axiom.co/ai/schemas/0.0.2`
- `axiom.gen_ai.sdk.name` - The name of the SDK (e.g., `my-ai-instrumentation-sdk`)
- `axiom.gen_ai.sdk.version` - The version of the SDK (e.g., `1.2.3`)

## Span naming

Span names should follow the OpenTelemetry conventions for generative AI spans. Below are the suggested span names for common values of [gen_ai.operation.name](#gen_ai.operation.name):

- `chat {gen_ai.request.model}`
- `execute_tool {gen_ai.tool.name}`
- `embeddings {gen_ai.request.model}`
- `generate_content {gen_ai.request.model}`
- `text_completion {gen_ai.request.model}`
- `create_agent {gen_ai.agent.name}`
- `invoke_agent {gen_ai.agent.name}`

More information:
- [AI spans](https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-spans/#spans)
- [Agent spans](https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-agent-spans/)
- [Tool span](https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-spans/#execute-tool-span)

## Other attributes

Beyond `gen_ai.operation.name`, `gen_ai.capability.name` and `gen_ai.step.name`, these attributes are recommended to get the most out of Axiom's AI telemetry features.

### Chat spans

| Attribute | Type | Required | Description |
| --------- | ---- | -------- | ----------- |
| `gen_ai.provider.name` | string | Required | Provider (openai, anthropic, aws.bedrock, etc.) |
| `gen_ai.request.model` | string | When available | Model requested (gpt-4, claude-3, etc.) |
| `gen_ai.response.model` | string | When available | Model that fulfilled the request |
| `gen_ai.input.messages` | Messages[] (stringified) | Recommended | Input conversation history |
| `gen_ai.output.messages` | Messages[] (stringified) | Recommended | Model response messages |
| `gen_ai.usage.input_tokens` | integer | Recommended | Input token count |
| `gen_ai.usage.output_tokens` | integer | Recommended | Output token count |
| `gen_ai.request.choice_count` | integer | When >1 | Number of completion choices requested |
| `gen_ai.response.id` | string | Recommended | Unique response identifier |
| `gen_ai.response.finish_reasons` | string[] | Recommended | Why generation stopped |
| `gen_ai.conversation.id` | string | When available | Conversation/session identifier |

### Tool spans

For tool operations (`execute_tool`), include these additional attributes:

| Attribute | Type | Required | Description |
| --------- | ---- | -------- | ----------- |
| `gen_ai.tool.name` | string | Required | Name of the executed tool |
| `gen_ai.tool.call.id` | string | When available | Tool call identifier |
| `gen_ai.tool.type` | string | When available | Tool type (function, extension, datastore) |
| `gen_ai.tool.description` | string | When available | Tool description |
| `gen_ai.tool.arguments` | string | When available | Tool arguments |
| `gen_ai.tool.message` | string | When available | Tool message |

For more information, see [Gen AI Attributes](https://opentelemetry.io/docs/specs/semconv/registry/attributes/gen-ai/#genai-attributes).

### Agent spans

For agent operations (`create_agent`, `invoke_agent`), include these additional attributes:

| Attribute | Type | Required | Description |
| --------- | ---- | -------- | ----------- |
| `gen_ai.agent.id` | string | When available | Unique agent identifier |
| `gen_ai.agent.name` | string | When available | Human-readable agent name |
| `gen_ai.agent.description` | string | When available | Agent description/purpose |
| `gen_ai.conversation.id` | string | When available | Conversation/session identifier |


## Messages

Messages support four different roles, each with specific content formats. They follow OpenTelemetry's structured format:

**System messages**
```json
{
  "role": "system",
  "parts": [
    {"type": "text", "content": "You are a helpful assistant"}
  ]
}
```

**User messages**
```json
{
  "role": "user",
  "parts": [
    {"type": "text", "content": "Weather in Paris?"}
  ]
}
```

**Assistant messages**
```json
{
  "role": "assistant", 
  "parts": [
    {"type": "text", "content": "Hi there!"},
    {"type": "tool_call", "id": "call_123", "name": "get_weather", "arguments": {"location": "Paris"}}
  ],
  "finish_reason": "stop"
}
```

**Tool messages**
```json
{
  "role": "tool",
  "parts": [
    {"type": "tool_call_response", "id": "call_123", "response": "rainy, 57Â°F"}
  ]
}
```

**Content part types:**
- `text` - Text content with `content` field
- `tool_call` - Tool invocation with `id`, `name`, `arguments`
- `tool_call_response` - Tool result with `id`, `response`

See more information in [Recording content on attributes](https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-spans/#recording-content-on-attributes), as well as the JSON schema for [inputs](https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-input-messages.json) and [outputs](https://opentelemetry.io/docs/specs/semconv/gen-ai/gen-ai-output-messages.json).

## Example trace structure

### Chat completion

Here is an example of a properly structured chat completion trace:

<CodeGroup>

```typescript TypeScript
import { trace, SpanKind, SpanStatusCode } from '@opentelemetry/api';

const tracer = trace.getTracer('my-ai-app');

// Create a span for the AI operation
return tracer.startActiveSpan('chat gpt-4', {
  kind: SpanKind.CLIENT
}, (span) => {
  try {
    // (Your AI operation logic here...)

    span.setAttributes({
      // Set operation name
      'gen_ai.operation.name': 'chat',
      // Set capability and step
      'gen_ai.capability.name': 'customer_support',
      'gen_ai.step.name': 'respond_to_greeting',
      // Set other attributes
      'gen_ai.provider.name': 'openai',
      'gen_ai.request.model': 'gpt-4',
      'gen_ai.response.model': 'gpt-4',
      'gen_ai.usage.input_tokens': 150,
      'gen_ai.usage.output_tokens': 75,
      'gen_ai.input.messages': JSON.stringify([
        { role: 'user', parts: [{ type: 'text', content: 'Hello, how are you?' }] }
      ]),
      'gen_ai.output.messages': JSON.stringify([
        { role: 'assistant', parts: [{ type: 'text', content: 'I\'m doing well, thank you!' }], finish_reason: 'stop' }
      ])
    });
    
    return /* your result */;
  } catch (error) {
    span.recordException(error);
    span.setStatus({ code: SpanStatusCode.ERROR, message: error.message });
    throw error; // rethrow if you want upstream to see it
  } finally {
    span.end();
  }
});
```

```python Python
from opentelemetry import trace
from opentelemetry.trace import SpanKind
import json

tracer = trace.get_tracer("my-ai-app")

# Create a span for the AI operation
with tracer.start_as_current_span("chat gpt-4", kind=SpanKind.CLIENT) as span:
    # (Your AI operation logic here...)

    span.set_attributes({
        # Set operation name
        "gen_ai.operation.name": "chat",
        # Set capability and step
        "gen_ai.capability.name": "customer_support",
        "gen_ai.step.name": "respond_to_greeting",
        # Set other attributes
        "gen_ai.provider.name": "openai",
        "gen_ai.request.model": "gpt-4",
        "gen_ai.response.model": "gpt-4",
        "gen_ai.usage.input_tokens": 150,
        "gen_ai.usage.output_tokens": 75,
        "gen_ai.input.messages": json.dumps([
            {"role": "user", "parts": [{"type": "text", "content": "Hello, how are you?"}]}
        ]),
        "gen_ai.output.messages": json.dumps([
            {"role": "assistant", "parts": [{"type": "text", "content": "I'm doing well, thank you!"}], "finish_reason": "stop"}
        ])
    })
    
```

</CodeGroup>

### Tool execution

Here is an example of a tool execution within an agent:

<CodeGroup>

```typescript Node.js
import { trace, SpanKind, SpanStatusCode } from '@opentelemetry/api';

const tracer = trace.getTracer('my-agent-app');

// Create a span for tool execution
return tracer.startActiveSpan('execute_tool get_weather', {
  kind: SpanKind.CLIENT
}, (span) => {
  try {
    // (Your tool call logic here...)

    span.setAttributes({
      // Set operation name
      'gen_ai.operation.name': 'execute_tool',
      // Set capability and step
      'gen_ai.capability.name': 'weather_assistance',
      'gen_ai.step.name': 'fetch_current_weather',
      // Set other attributes
      'gen_ai.tool.name': 'get_weather',
      'gen_ai.tool.type': 'function',
      'gen_ai.tool.call.id': 'call_abc123',
      'gen_ai.tool.arguments': JSON.stringify({ location: 'New York', units: 'celsius' }),
      'gen_ai.tool.message': JSON.stringify({ temperature: 22, condition: 'sunny', humidity: 65 }),
    });
    
    return /* your result */;
  } catch (error) {
    span.recordException(error);
    span.setStatus({ code: SpanStatusCode.ERROR, message: error.message });
    throw error; // rethrow if you want upstream to see it
  } finally {
    span.end();
  }
});
```

```python Python
from opentelemetry import trace
from opentelemetry.trace import SpanKind
import json

tracer = trace.get_tracer("my-agent-app")

# Create a span for tool execution  
with tracer.start_as_current_span("execute_tool get_weather", kind=SpanKind.CLIENT) as span:
    span.set_attributes({
        # Set operation name
        "gen_ai.operation.name": "execute_tool",
        # Set capability and step
        "gen_ai.step.name": "fetch_current_weather",
        "gen_ai.capability.name": "weather_assistance",
        # Set other attributes
        "gen_ai.tool.name": "get_weather",
        "gen_ai.tool.type": "function",
        "gen_ai.tool.call.id": "call_abc123",
        "gen_ai.tool.arguments": json.dumps({"location": "New York", "units": "celsius"}),
        "gen_ai.tool.message": json.dumps({"temperature": 22, "condition": "sunny", "humidity": 65}),
    })
```

</CodeGroup>

## What's next?

Once you're sending traces with the proper semantic conventions:

- View your [traces](/query-data/traces) in Axiom's Console
- Set up [monitors and alerts](/monitor-data/monitors) based on your AI telemetry data
- Learn about [developing AI features](/ai-engineering/create) with confidence using Axiom

Prefer the fastest route with zero configuration? See the [TypeScript SDK](/ai-engineering/observe/typescript-sdk) for a wrapper around the Vercel AI SDK.
