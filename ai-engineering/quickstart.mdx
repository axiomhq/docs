---
title: "Quickstart"
description: "Install and configure the Axiom AI SDK to begin capturing telemetry from your generative AI applications."
keywords: ["ai engineering", "getting started", "install", "setup", "configuration", "opentelemetry"]
---

import AIEngineeringInstrumentationSnippet from '/snippets/ai-engineering-instrumentation.mdx'
import ReplaceDatasetToken from "/snippets/replace-dataset-token.mdx"

This guide provides the steps to install and configure Axiom’s [AI SDK](https://github.com/axiomhq/ai). Once configured, you can follow the Rudder workflow to create, measure, observe, and iterate on your capabilities.

## Integration approaches

Axiom offers two ways to capture generative AI telemetry:

<CardGroup cols={2}>
  <Card title="Axiom AI SDK" icon="bolt" href="#installation">
    **TypeScript** - Use with the Vercel AI SDK for automatic instrumentation with minimal code changes. Follow this guide to get started.
  </Card>
  <Card title="Custom OpenTelemetry" icon="code" href="/ai-engineering/observe/manual-instrumentation">
    **Language-agnostic OpenTelemetry** - Send traces using your own tooling by following our semantic conventions. Works with any language or SDK.
  </Card>
</CardGroup>

## Prerequisites

Before you begin, ensure you have the following:

* An Axiom **account**. Create one [here](https://www.axiom.co/register).
* An Axiom **dataset**. Create one [here](https://app.axiom.co/datasets).
* An Axiom **API token**. Create one [here](https://app.axiom.co/settings/api-tokens).

## Installation

Install the Axiom AI SDK into your TypeScript project using your preferred package manager.

<CodeGroup>

```bash pnpm
pnpm i axiom
```

```bash npm
npm i axiom
```

```bash yarn
yarn add axiom
```

```bash bun
bun add axiom
```

</CodeGroup>

The SDK is open source. You can view the source code and examples in Axiom’s [AI SDK](https://github.com/axiomhq/ai) GitHub repository.

<Tip>
The `axiom` package includes the `axiom` command-line interface (CLI) for managing your AI assets, which will be used in later stages of the Rudder workflow.
</Tip>

## Configuration

Axiom’s AI SDK is built on the OpenTelemetry standard and requires a configured tracer to send data to Axiom. This is typically done in a dedicated instrumentation file that’s loaded before the rest of your application.

Here is a standard configuration for a Node.js environment:

<CodeGroup>

```bash pnpm
pnpm i \
  dotenv \
  @opentelemetry/exporter-trace-otlp-http \
  @opentelemetry/resources \
  @opentelemetry/sdk-node \
  @opentelemetry/sdk-trace-node \
  @opentelemetry/semantic-conventions \
  @opentelemetry/api
```

```bash npm
npm i \
  dotenv \
  @opentelemetry/exporter-trace-otlp-http \
  @opentelemetry/resources \
  @opentelemetry/sdk-node \
  @opentelemetry/sdk-trace-node \
  @opentelemetry/semantic-conventions \
  @opentelemetry/api
```

```bash yarn
yarn add \
  dotenv \
  @opentelemetry/exporter-trace-otlp-http \
  @opentelemetry/resources \
  @opentelemetry/sdk-node \
  @opentelemetry/sdk-trace-node \
  @opentelemetry/semantic-conventions \
  @opentelemetry/api
```

```bash bun
bun add \
  dotenv \
  @opentelemetry/exporter-trace-otlp-http \
  @opentelemetry/resources \
  @opentelemetry/sdk-node \
  @opentelemetry/sdk-trace-node \
  @opentelemetry/semantic-conventions \
  @opentelemetry/api
```

</CodeGroup>

<AIEngineeringInstrumentationSnippet />

## Environment variables

Your Axiom credentials and any frontier model API keys should be stored as environment variables. Create a `.env` file in the root of your project:

```bash
# Axiom Credentials
AXIOM_TOKEN="API_TOKEN"
AXIOM_DATASET="DATASET_NAME"

# Frontier Model API Keys
OPENAI_API_KEY="OPENAI_API_KEY"
GEMINI_API_KEY="GEMINI_API_KEY"
```

<Info>
<ReplaceDatasetToken />
</Info>

## What’s next?

Now that your application is configured to send telemetry to Axiom, you have several paths forward:

* **Continue with Axiom AI SDK**: Learn about instrumenting your AI model and tool calls in the [Observe](/ai-engineering/observe/introduction) page.
* **Switch to custom tooling**: If you prefer to use your own instrumentation, see the [Manual Instrumentation](/ai-engineering/observe/manual-instrumentation) page.
* **Explore the Rudder workflow**: Start building systematic AI capabilities beginning with [Create](/ai-engineering/create).