---
title: "Set up online evaluations"
description: "Install the Axiom AI SDK and authenticate to run online evaluations."
keywords: ["ai engineering", "setup", "authentication", "cli", "install"]
sidebarTitle: "Set up and authenticate"
---

import ReplaceDomain from "/snippets/replace-domain.mdx"
import ReplaceDatasetToken from "/snippets/replace-dataset-token.mdx"
import ReplaceOrgId from "/snippets/replace-org-id.mdx"
import Prerequisites from "/snippets/standard-prerequisites.mdx"

This page explains how to install Axiom AI SDK and configure your environment for online evaluations so that your evaluation results are tracked and attributed correctly in the Axiom Console.

<Prerequisites />
- Install [Node.js](https://nodejs.org/en/download/package-manager) version 18 or later.
- A TypeScript or JavaScript project. Evaluations work best with TypeScript frameworks like Vercel AI SDK.

## Install Axiom AI SDK

Install the `axiom` package in your project:

```bash
npm install axiom
```

This package provides:
- The `Eval` function for defining online evaluations
- The `onlineEval` function for scoring live production traffic
- The `Scorer` wrapper for creating custom scorers
- Instrumentation helpers for capturing AI telemetry

## Authenticate with environment variables

Authenticate using environment variables:

```bash 
export AXIOM_TOKEN="API_TOKEN"
export AXIOM_DATASET="DATASET_NAME"
export AXIOM_ORG_ID="ORGANIZATION_ID"
export AXIOM_URL="AXIOM_DOMAIN"
```

<Info>
<ReplaceDatasetToken />
<ReplaceOrgId />
<ReplaceDomain />
</Info>

## Set up instrumentation

Initialize OpenTelemetry tracing so evaluation runs are captured as traces in Axiom. Create a file to set up your tracing provider:

```ts src/instrumentation.ts
import { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-http';
import { NodeTracerProvider } from '@opentelemetry/sdk-trace-node';
import { BatchSpanProcessor } from '@opentelemetry/sdk-trace-node';
import { initAxiomAI } from 'axiom/ai';
import type { AxiomEvalInstrumentationHook } from 'axiom/ai/config';

let provider: NodeTracerProvider | undefined;

export const setupAppInstrumentation: AxiomEvalInstrumentationHook = async (options) => {
  if (provider) {
    return { provider };
  }

  const exporter = new OTLPTraceExporter({
    url: `${options.url}/v1/traces`,
    headers: {
      Authorization: `Bearer ${options.token}`,
      'X-Axiom-Dataset': options.dataset,
      ...(options.orgId ? { 'X-AXIOM-ORG-ID': options.orgId } : {}),
    },
  });

  provider = new NodeTracerProvider({
    spanProcessors: [new BatchSpanProcessor(exporter)],
  });

  provider.register();
  
  // Initialize Axiom AI instrumentation
  initAxiomAI({ 
    tracer: provider.getTracer('axiom-ai'),
  });

  return { provider };
};
```

<Tip>
If youâ€™re already using Axiom for observability in your application, you can reuse your existing tracing setup. The evaluation framework integrates seamlessly with your existing instrumentation.
</Tip>

## What's next?

- To write and run online evaluation functions, see [Write and run online evaluations](/ai-engineering/evaluate/online-evaluations/write-run-evaluations).
- To analyze online evaluation results, see [Analyze online evaluation results](/ai-engineering/evaluate/online-evaluations/analyze-results).
